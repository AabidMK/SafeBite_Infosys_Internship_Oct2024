{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc6a6ab-4e79-4e5e-a5dd-7f2007c2ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 399 entries, 0 to 398\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Food Product                399 non-null    object \n",
      " 1   Main Ingredient             399 non-null    object \n",
      " 2   Sweetener                   119 non-null    object \n",
      " 3   Fat/Oil                     341 non-null    object \n",
      " 4   Seasoning                   379 non-null    object \n",
      " 5   Allergens                   251 non-null    object \n",
      " 6   Price ($)                   399 non-null    float64\n",
      " 7   Customer rating (Out of 5)  399 non-null    float64\n",
      " 8   Prediction                  398 non-null    object \n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 28.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "           Food Product Main Ingredient Sweetener Fat/Oil Seasoning  \\\n",
       " 0       Almond Cookies         Almonds     Sugar  Butter     Flour   \n",
       " 1       Almond Cookies         Almonds     Sugar  Butter     Flour   \n",
       " 2  Chicken Noodle Soup   Chicken broth       NaN     NaN      Salt   \n",
       " 3  Chicken Noodle Soup   Chicken broth       NaN     NaN      Salt   \n",
       " 4       Cheddar Cheese          Cheese       NaN     NaN      Salt   \n",
       " \n",
       "                 Allergens  Price ($)  Customer rating (Out of 5) Prediction  \n",
       " 0   Almonds, Wheat, Dairy      10.15                         3.1   Contains  \n",
       " 1   Almonds, Wheat, Dairy       6.17                         4.5   Contains  \n",
       " 2  Chicken, Wheat, Celery      19.65                         4.1   Contains  \n",
       " 3  Chicken, Wheat, Celery      17.48                         4.7   Contains  \n",
       " 4                   Dairy      10.83                         3.7   Contains  )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'C:/Users/gunde/Downloads/Allergen_Status_of_Food_Products (2).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and general info of the data to understand its structure\n",
    "data_info = data.info()\n",
    "data_head = data.head()\n",
    "\n",
    "data_info, data_head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81356c5a-36b7-4ddf-aab4-23f554c19c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunde\\AppData\\Local\\Temp\\ipykernel_19248\\1129615876.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Prediction'].fillna(data['Prediction'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Food Product                    0\n",
       " Main Ingredient                 0\n",
       " Sweetener                     280\n",
       " Fat/Oil                        58\n",
       " Seasoning                      20\n",
       " Allergens                     148\n",
       " Price ($)                       0\n",
       " Customer rating (Out of 5)      0\n",
       " Prediction                      1\n",
       " dtype: int64,\n",
       " 0,\n",
       " {'Price ($)': 0, 'Customer rating (Out of 5)': 0},\n",
       "    Price ($)  Customer rating (Out of 5)  Prediction  \\\n",
       " 0      10.15                         3.1           0   \n",
       " 1       6.17                         4.5           0   \n",
       " 2      19.65                         4.1           0   \n",
       " 3      17.48                         4.7           0   \n",
       " 4      10.83                         3.7           0   \n",
       " \n",
       "    Food Product_Almond Cookies  Food Product_Aloo Gobi  \\\n",
       " 0                         True                   False   \n",
       " 1                         True                   False   \n",
       " 2                        False                   False   \n",
       " 3                        False                   False   \n",
       " 4                        False                   False   \n",
       " \n",
       "    Food Product_Aloo Paratha  Food Product_Apple  Food Product_Apple Cider  \\\n",
       " 0                      False               False                     False   \n",
       " 1                      False               False                     False   \n",
       " 2                      False               False                     False   \n",
       " 3                      False               False                     False   \n",
       " 4                      False               False                     False   \n",
       " \n",
       "    Food Product_Apple Crisp  Food Product_Apple Pie  ...  \\\n",
       " 0                     False                   False  ...   \n",
       " 1                     False                   False  ...   \n",
       " 2                     False                   False  ...   \n",
       " 3                     False                   False  ...   \n",
       " 4                     False                   False  ...   \n",
       " \n",
       "    Allergens_Shellfish, Soybeans  Allergens_Soybeans  \\\n",
       " 0                          False               False   \n",
       " 1                          False               False   \n",
       " 2                          False               False   \n",
       " 3                          False               False   \n",
       " 4                          False               False   \n",
       " \n",
       "    Allergens_Soybeans, Fish  Allergens_Wheat  Allergens_Wheat, Dairy  \\\n",
       " 0                     False            False                   False   \n",
       " 1                     False            False                   False   \n",
       " 2                     False            False                   False   \n",
       " 3                     False            False                   False   \n",
       " 4                     False            False                   False   \n",
       " \n",
       "    Allergens_Wheat, Dairy, Alcohol  Allergens_Wheat, Dairy, Cocoa  \\\n",
       " 0                            False                          False   \n",
       " 1                            False                          False   \n",
       " 2                            False                          False   \n",
       " 3                            False                          False   \n",
       " 4                            False                          False   \n",
       " \n",
       "    Allergens_Wheat, Dairy, Eggs  Allergens_Wheat, Dairy, Nuts  \\\n",
       " 0                         False                         False   \n",
       " 1                         False                         False   \n",
       " 2                         False                         False   \n",
       " 3                         False                         False   \n",
       " 4                         False                         False   \n",
       " \n",
       "    Allergens_Wheat, Pork, Dairy  \n",
       " 0                         False  \n",
       " 1                         False  \n",
       " 2                         False  \n",
       " 3                         False  \n",
       " 4                         False  \n",
       " \n",
       " [5 rows x 631 columns])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Handle missing values by dropping or imputing (we'll use imputation for \"Prediction\")\n",
    "# Check how many missing values are in each column\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Impute the missing value in 'Prediction' with the most frequent value\n",
    "data['Prediction'].fillna(data['Prediction'].mode()[0], inplace=True)\n",
    "\n",
    "# Step 2: Check for duplicates in the dataset\n",
    "duplicates = data.duplicated().sum()\n",
    "\n",
    "# Step 3: Check for outliers in numerical columns using IQR method\n",
    "# Outliers will be detected but not removed\n",
    "numeric_columns = ['Price ($)', 'Customer rating (Out of 5)']\n",
    "outliers_info = {}\n",
    "for column in numeric_columns:\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((data[column] < lower_bound) | (data[column] > upper_bound)).sum()\n",
    "    outliers_info[column] = outliers\n",
    "\n",
    "# Step 4: Encoding categorical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label Encoding for the Prediction column\n",
    "label_encoder = LabelEncoder()\n",
    "data['Prediction'] = label_encoder.fit_transform(data['Prediction'])\n",
    "\n",
    "# One-hot encoding for categorical feature columns\n",
    "encoded_data = pd.get_dummies(data, columns=['Food Product', 'Main Ingredient', 'Sweetener', \n",
    "                                             'Fat/Oil', 'Seasoning', 'Allergens'])\n",
    "\n",
    "# Output results to verify each step\n",
    "missing_values, duplicates, outliers_info, encoded_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "059b93fe-9cdc-48a5-a973-7141fe4c832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Code to check for duplicates without removing any rows\n",
    "# Code to check for duplicates without removing any rows\n",
    "duplicates_count = data.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicates_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "687cd7e8-da34-4d6f-97fe-6057ec9752f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers information: {'Price ($)': 0, 'Customer rating (Out of 5)': 0}\n"
     ]
    }
   ],
   "source": [
    "# List of numerical columns to check for outliers\n",
    "numeric_columns = ['Price ($)', 'Customer rating (Out of 5)']\n",
    "\n",
    "# Dictionary to store outlier counts for each column\n",
    "outliers_info = {}\n",
    "\n",
    "# IQR method to check for outliers\n",
    "for column in numeric_columns:\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Count of outliers in each column\n",
    "    outliers = ((data[column] < lower_bound) | (data[column] > upper_bound)).sum()\n",
    "    outliers_info[column] = outliers\n",
    "\n",
    "print(\"Outliers information:\", outliers_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3dc827c-0c29-4d82-88ef-0d3cb7f4098d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the plot canvas for side-by-side boxplots\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the box plot for \"Price ($)\"\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=data['Price ($)'])\n",
    "plt.title('Box Plot of Price ($)')\n",
    "\n",
    "# Plot the box plot for \"Customer rating (Out of 5)\"\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=data['Customer rating (Out of 5)'])\n",
    "plt.title('Box Plot of Customer Rating')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e122665-296a-4dce-a944-98c6da6091ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Food Product Main Ingredient Sweetener Fat/Oil Seasoning              Allergens  Price ($)  Customer rating (Out of 5)  Prediction\n",
      "     Almond Cookies         Almonds     Sugar  Butter     Flour  Almonds, Wheat, Dairy      10.15                         3.1           0\n",
      "     Almond Cookies         Almonds     Sugar  Butter     Flour  Almonds, Wheat, Dairy       6.17                         4.5           0\n",
      "Chicken Noodle Soup   Chicken broth       NaN     NaN      Salt Chicken, Wheat, Celery      19.65                         4.1           0\n",
      "Chicken Noodle Soup   Chicken broth       NaN     NaN      Salt Chicken, Wheat, Celery      17.48                         4.7           0\n",
      "     Cheddar Cheese          Cheese       NaN     NaN      Salt                  Dairy      10.83                         3.7           0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label encode the 'Prediction' column\n",
    "label_encoder = LabelEncoder()\n",
    "data['Prediction'] = label_encoder.fit_transform(data['Prediction'])\n",
    "\n",
    "# Display the first few rows in a tabular format\n",
    "print(data.head().to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d60e17db-040f-472a-bcc6-3c6f441381a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Product</th>\n",
       "      <th>Main Ingredient</th>\n",
       "      <th>Sweetener</th>\n",
       "      <th>Fat/Oil</th>\n",
       "      <th>Seasoning</th>\n",
       "      <th>Allergens</th>\n",
       "      <th>Price ($)</th>\n",
       "      <th>Customer rating (Out of 5)</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Food Product_Freq</th>\n",
       "      <th>Main Ingredient_Freq</th>\n",
       "      <th>Sweetener_Freq</th>\n",
       "      <th>Fat/Oil_Freq</th>\n",
       "      <th>Seasoning_Freq</th>\n",
       "      <th>Allergens_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Almond Cookies</td>\n",
       "      <td>Almonds</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Flour</td>\n",
       "      <td>Almonds, Wheat, Dairy</td>\n",
       "      <td>10.15</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.249267</td>\n",
       "      <td>0.029024</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Almond Cookies</td>\n",
       "      <td>Almonds</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Flour</td>\n",
       "      <td>Almonds, Wheat, Dairy</td>\n",
       "      <td>6.17</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.249267</td>\n",
       "      <td>0.029024</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicken Noodle Soup</td>\n",
       "      <td>Chicken broth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salt</td>\n",
       "      <td>Chicken, Wheat, Celery</td>\n",
       "      <td>19.65</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029024</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Noodle Soup</td>\n",
       "      <td>Chicken broth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salt</td>\n",
       "      <td>Chicken, Wheat, Celery</td>\n",
       "      <td>17.48</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029024</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cheddar Cheese</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salt</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>10.83</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029024</td>\n",
       "      <td>0.330677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Food Product Main Ingredient Sweetener Fat/Oil Seasoning  \\\n",
       "0       Almond Cookies         Almonds     Sugar  Butter     Flour   \n",
       "1       Almond Cookies         Almonds     Sugar  Butter     Flour   \n",
       "2  Chicken Noodle Soup   Chicken broth       NaN     NaN      Salt   \n",
       "3  Chicken Noodle Soup   Chicken broth       NaN     NaN      Salt   \n",
       "4       Cheddar Cheese          Cheese       NaN     NaN      Salt   \n",
       "\n",
       "                Allergens  Price ($)  Customer rating (Out of 5)  Prediction  \\\n",
       "0   Almonds, Wheat, Dairy      10.15                         3.1           0   \n",
       "1   Almonds, Wheat, Dairy       6.17                         4.5           0   \n",
       "2  Chicken, Wheat, Celery      19.65                         4.1           0   \n",
       "3  Chicken, Wheat, Celery      17.48                         4.7           0   \n",
       "4                   Dairy      10.83                         3.7           0   \n",
       "\n",
       "   Food Product_Freq  Main Ingredient_Freq  Sweetener_Freq  Fat/Oil_Freq  \\\n",
       "0           0.005013              0.005013        0.773109      0.249267   \n",
       "1           0.005013              0.005013        0.773109      0.249267   \n",
       "2           0.010025              0.005013             NaN           NaN   \n",
       "3           0.010025              0.005013             NaN           NaN   \n",
       "4           0.002506              0.007519             NaN           NaN   \n",
       "\n",
       "   Seasoning_Freq  Allergens_Freq  \n",
       "0        0.029024        0.007968  \n",
       "1        0.029024        0.007968  \n",
       "2        0.029024        0.007968  \n",
       "3        0.029024        0.007968  \n",
       "4        0.029024        0.330677  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label encode the 'Prediction' column\n",
    "label_encoder = LabelEncoder()\n",
    "data['Prediction'] = label_encoder.fit_transform(data['Prediction'])\n",
    "\n",
    "# Step 2: Frequency encoding for specified columns and appending \"_Freq\" to encoded columns\n",
    "categorical_columns = ['Food Product', 'Main Ingredient', 'Sweetener', 'Fat/Oil', 'Seasoning', 'Allergens']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    freq_encoding = data[column].value_counts(normalize=True)\n",
    "    data[column + '_Freq'] = data[column].map(freq_encoding)\n",
    "\n",
    "# Display the first few rows in a beautiful HTML table (only for Jupyter)\n",
    "from IPython.display import display\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "affaf240-0041-4bb9-bc87-6554b4f2b22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 70:30 split (in %): 94.16666666666667\n",
      "\n",
      "Classification Report on 70:30 split:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        87\n",
      "           1       0.88      0.91      0.90        33\n",
      "\n",
      "    accuracy                           0.94       120\n",
      "   macro avg       0.92      0.93      0.93       120\n",
      "weighted avg       0.94      0.94      0.94       120\n",
      "\n",
      "Confusion Matrix on 70:30 split:\n",
      " [[83  4]\n",
      " [ 3 30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data (replace with actual file path if needed)\n",
    "data = pd.read_csv('C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv')\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the encoded data into 70:30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_70 = accuracy_score(y_test, y_pred) * 100\n",
    "print(\"Accuracy on 70:30 split (in %):\", accuracy_70)\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report on 70:30 split:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix on 70:30 split:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5e6b7bc-c9ab-4287-a3e4-a57697415bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 80:20 split (in %): 97.5\n",
      "\n",
      "Classification Report on 80:20 split:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        58\n",
      "           1       0.95      0.95      0.95        22\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.97      0.97      0.97        80\n",
      "weighted avg       0.97      0.97      0.97        80\n",
      "\n",
      "Confusion Matrix on 80:20 split:\n",
      " [[57  1]\n",
      " [ 1 21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data (replace with actual file path if needed)\n",
    "data = pd.read_csv('C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv')\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the encoded data into 80:20\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_80, y_train_80)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_80 = logreg.predict(X_test_80)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_80 = accuracy_score(y_test_80, y_pred_80) * 100\n",
    "print(\"Accuracy on 80:20 split (in %):\", accuracy_80)\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report on 80:20 split:\\n\", classification_report(y_test_80, y_pred_80))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix on 80:20 split:\\n\", confusion_matrix(y_test_80, y_pred_80))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6bcad32-c557-4579-9d2d-42e3205ff7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for 80:20 split using KNN model : 90.00% \n",
      "Best accuracy for 70:30 split using KNN model : 88.33% \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Split the dataset into X (features) and y (target variable)\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encoding categorical features to numerical values\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Encoding the target variable\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Define the range of k values to test\n",
    "k_values = range(1, 21)\n",
    "\n",
    "# Perform both 80:20 and 70:30 train-test splits\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize variables to store the best k and accuracy for each split\n",
    "best_k_80_20, best_accuracy_80_20 = 0, 0\n",
    "best_k_70_30, best_accuracy_70_30 = 0, 0\n",
    "\n",
    "# Iterate over each k value, train the model, and evaluate accuracy for both splits\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # 80:20 split accuracy\n",
    "    knn.fit(X_train_80, y_train_80)\n",
    "    y_pred_80 = knn.predict(X_test_80)\n",
    "    accuracy_80_20 = accuracy_score(y_test_80, y_pred_80) * 100\n",
    "    if accuracy_80_20 > best_accuracy_80_20:\n",
    "        best_k_80_20 = k\n",
    "        best_accuracy_80_20 = accuracy_80_20\n",
    "    \n",
    "    # 70:30 split accuracy\n",
    "    knn.fit(X_train_70, y_train_70)\n",
    "    y_pred_70 = knn.predict(X_test_70)\n",
    "    accuracy_70_30 = accuracy_score(y_test_70, y_pred_70) * 100\n",
    "    if accuracy_70_30 > best_accuracy_70_30:\n",
    "        best_k_70_30 = k\n",
    "        best_accuracy_70_30 = accuracy_70_30\n",
    "\n",
    "# Display the best results for each split\n",
    "print(f\"Best accuracy for 80:20 split using KNN model : {best_accuracy_80_20:.2f}% \")\n",
    "print(f\"Best accuracy for 70:30 split using KNN model : {best_accuracy_70_30:.2f}% \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "547281fd-570f-4e65-ae6c-ebf255d1318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy for 80:20 split using Random forest model : 98.75% \n",
      " accuracy for 70:30 split using Random forest model : 99.17% \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Encoding categorical features to numerical values\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Encoding the target variable\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Define the random forest classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform both 80:20 and 70:30 train-test splits\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training and evaluating the model on the 80:20 split\n",
    "rf_clf.fit(X_train_80, y_train_80)\n",
    "y_pred_80 = rf_clf.predict(X_test_80)\n",
    "accuracy_80_20 = accuracy_score(y_test_80, y_pred_80) * 100\n",
    "\n",
    "# Training and evaluating the model on the 70:30 split\n",
    "rf_clf.fit(X_train_70, y_train_70)\n",
    "y_pred_70 = rf_clf.predict(X_test_70)\n",
    "accuracy_70_30 = accuracy_score(y_test_70, y_pred_70) * 100\n",
    "\n",
    "print(f\" accuracy for 80:20 split using Random forest model : {accuracy_80_20:.2f}% \")\n",
    "print(f\" accuracy for 70:30 split using Random forest model : {accuracy_70_30:.2f}% \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "254d7e44-6b47-42e8-b779-ab14233264d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy for 80:20 split: 98.75%\n",
      "Decision Tree accuracy for 70:30 split: 98.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load and encode data as in the previous examples\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Split data for 80:20 and 70:30 ratios\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define and train the Decision Tree classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 80:20 split evaluation\n",
    "dt_clf.fit(X_train_80, y_train_80)\n",
    "y_pred_80_dt = dt_clf.predict(X_test_80)\n",
    "accuracy_80_20_dt = accuracy_score(y_test_80, y_pred_80_dt) * 100\n",
    "\n",
    "\n",
    "# 70:30 split evaluation\n",
    "dt_clf.fit(X_train_70, y_train_70)\n",
    "y_pred_70_dt = dt_clf.predict(X_test_70)\n",
    "accuracy_70_30_dt = accuracy_score(y_test_70, y_pred_70_dt) * 100\n",
    "\n",
    "\n",
    "print(f\"Decision Tree accuracy for 80:20 split: {accuracy_80_20_dt:.2f}%\")\n",
    "print(f\"Decision Tree accuracy for 70:30 split: {accuracy_70_30_dt:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37efc7a7-d5ed-4c13-a870-0509fde5212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Train accuracy for 80:20 split: 98.12%\n",
      "Naive Bayes Test accuracy for 80:20 split: 96.25%\n",
      "Naive Bayes Train accuracy for 70:30 split: 98.21%\n",
      "Naive Bayes Test accuracy for 70:30 split: 96.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load and encode data as in the previous examples\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Split data for 80:20 and 70:30 ratios\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "# Naive Bayes model\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# 80:20 split with Naive Bayes\n",
    "nb_clf.fit(X_train_80, y_train_80)\n",
    "y_train_pred_80_nb = nb_clf.predict(X_train_80)\n",
    "y_test_pred_80_nb = nb_clf.predict(X_test_80)\n",
    "train_accuracy_80_20_nb = accuracy_score(y_train_80, y_train_pred_80_nb) * 100\n",
    "test_accuracy_80_20_nb = accuracy_score(y_test_80, y_test_pred_80_nb) * 100\n",
    "\n",
    "# 70:30 split with Naive Bayes\n",
    "nb_clf.fit(X_train_70, y_train_70)\n",
    "y_train_pred_70_nb = nb_clf.predict(X_train_70)\n",
    "y_test_pred_70_nb = nb_clf.predict(X_test_70)\n",
    "train_accuracy_70_30_nb = accuracy_score(y_train_70, y_train_pred_70_nb) * 100\n",
    "test_accuracy_70_30_nb = accuracy_score(y_test_70, y_test_pred_70_nb) * 100\n",
    "\n",
    "print(f\"Naive Bayes Train accuracy for 80:20 split: {train_accuracy_80_20_nb:.2f}%\")\n",
    "print(f\"Naive Bayes Test accuracy for 80:20 split: {test_accuracy_80_20_nb:.2f}%\")\n",
    "print(f\"Naive Bayes Train accuracy for 70:30 split: {train_accuracy_70_30_nb:.2f}%\")\n",
    "print(f\"Naive Bayes Test accuracy for 70:30 split: {test_accuracy_70_30_nb:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25c5a9da-47ee-402a-8311-2083951a1926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Train accuracy for 80:20 split: 98.43%\n",
      "AdaBoost Test accuracy for 80:20 split: 98.75%\n",
      "AdaBoost Train accuracy for 70:30 split: 98.21%\n",
      "AdaBoost Test accuracy for 70:30 split: 99.17%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load and encode data\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encoding categorical features and target variable\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Split data for 80:20 and 70:30 ratios\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# AdaBoost model with SAMME algorithm\n",
    "ada_clf = AdaBoostClassifier(random_state=42, algorithm=\"SAMME\")\n",
    "\n",
    "# 80:20 split with AdaBoost\n",
    "ada_clf.fit(X_train_80, y_train_80)\n",
    "y_train_pred_80_ada = ada_clf.predict(X_train_80)\n",
    "y_test_pred_80_ada = ada_clf.predict(X_test_80)\n",
    "train_accuracy_80_20_ada = accuracy_score(y_train_80, y_train_pred_80_ada) * 100\n",
    "test_accuracy_80_20_ada = accuracy_score(y_test_80, y_test_pred_80_ada) * 100\n",
    "\n",
    "# 70:30 split with AdaBoost\n",
    "ada_clf.fit(X_train_70, y_train_70)\n",
    "y_train_pred_70_ada = ada_clf.predict(X_train_70)\n",
    "y_test_pred_70_ada = ada_clf.predict(X_test_70)\n",
    "train_accuracy_70_30_ada = accuracy_score(y_train_70, y_train_pred_70_ada) * 100\n",
    "test_accuracy_70_30_ada = accuracy_score(y_test_70, y_test_pred_70_ada) * 100\n",
    "\n",
    "print(f\"AdaBoost Train accuracy for 80:20 split: {train_accuracy_80_20_ada:.2f}%\")\n",
    "print(f\"AdaBoost Test accuracy for 80:20 split: {test_accuracy_80_20_ada:.2f}%\")\n",
    "print(f\"AdaBoost Train accuracy for 70:30 split: {train_accuracy_70_30_ada:.2f}%\")\n",
    "print(f\"AdaBoost Test accuracy for 70:30 split: {test_accuracy_70_30_ada:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeaf712e-49c8-4627-b213-5782c027015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Algorithm Split Ratio  Training Accuracy  Testing Accuracy\n",
      "0  K-Nearest Neighbors       80:20          92.163009         88.750000\n",
      "1  K-Nearest Neighbors       70:30          91.397849         79.166667\n",
      "2  Logistic Regression       80:20         100.000000         93.750000\n",
      "3  Logistic Regression       70:30         100.000000         90.833333\n",
      "4             AdaBoost       80:20          91.222571         88.750000\n",
      "5             AdaBoost       70:30          89.247312         80.833333\n",
      "6          Naive Bayes       80:20         100.000000         88.750000\n",
      "7          Naive Bayes       70:30         100.000000         87.500000\n",
      "8        Decision Tree       80:20         100.000000         90.000000\n",
      "9        Decision Tree       70:30         100.000000         92.500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv')\n",
    "\n",
    "# Fill missing values with the mode of each column\n",
    "data = data.fillna(data.mode().iloc[0])\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = data.drop('Prediction', axis=1)  # Using \"Prediction\" as the target column\n",
    "y = data['Prediction']\n",
    "\n",
    "# Convert categorical features to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Perform train-test splits in both 80:20 and 70:30 ratios\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define models to train with modified AdaBoost parameters\n",
    "models = {\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=300),\n",
    "    'AdaBoost': AdaBoostClassifier(algorithm='SAMME'),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each model using both splits\n",
    "for name, model in models.items():\n",
    "    # 80:20 split training and evaluation\n",
    "    model.fit(X_train_80, y_train_80)\n",
    "    train_accuracy_80 = accuracy_score(y_train_80, model.predict(X_train_80)) * 100\n",
    "    test_accuracy_80 = accuracy_score(y_test_80, model.predict(X_test_80)) * 100\n",
    "    results.append([name, '80:20', train_accuracy_80, test_accuracy_80])\n",
    "    \n",
    "    # 70:30 split training and evaluation\n",
    "    model.fit(X_train_70, y_train_70)\n",
    "    train_accuracy_70 = accuracy_score(y_train_70, model.predict(X_train_70)) * 100\n",
    "    test_accuracy_70 = accuracy_score(y_test_70, model.predict(X_test_70)) * 100\n",
    "    results.append([name, '70:30', train_accuracy_70, test_accuracy_70])\n",
    "\n",
    "# Convert results to DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results, columns=['Algorithm', 'Split Ratio', 'Training Accuracy', 'Testing Accuracy'])\n",
    "\n",
    "# Display the final results table\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17cbd62d-34d0-445e-9dff-e307efce9542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Train accuracy for 80:20 split: 98.43%\n",
      "AdaBoost Test accuracy for 80:20 split: 98.75%\n",
      "AdaBoost Train accuracy for 70:30 split: 98.21%\n",
      "AdaBoost Test accuracy for 70:30 split: 99.17%\n"
     ]
    }
   ],
   "source": [
    "# adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load and encode data\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encoding categorical features and target variable\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Split data for 80:20 and 70:30 ratios\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# AdaBoost model with SAMME algorithm\n",
    "ada_clf = AdaBoostClassifier(random_state=42, algorithm=\"SAMME\")\n",
    "\n",
    "# 80:20 split with AdaBoost\n",
    "ada_clf.fit(X_train_80, y_train_80)\n",
    "y_train_pred_80_ada = ada_clf.predict(X_train_80)\n",
    "y_test_pred_80_ada = ada_clf.predict(X_test_80)\n",
    "train_accuracy_80_20_ada = accuracy_score(y_train_80, y_train_pred_80_ada) * 100\n",
    "test_accuracy_80_20_ada = accuracy_score(y_test_80, y_test_pred_80_ada) * 100\n",
    "\n",
    "# 70:30 split with AdaBoost\n",
    "ada_clf.fit(X_train_70, y_train_70)\n",
    "y_train_pred_70_ada = ada_clf.predict(X_train_70)\n",
    "y_test_pred_70_ada = ada_clf.predict(X_test_70)\n",
    "train_accuracy_70_30_ada = accuracy_score(y_train_70, y_train_pred_70_ada) * 100\n",
    "test_accuracy_70_30_ada = accuracy_score(y_test_70, y_test_pred_70_ada) * 100\n",
    "\n",
    "print(f\"AdaBoost Train accuracy for 80:20 split: {train_accuracy_80_20_ada:.2f}%\")\n",
    "print(f\"AdaBoost Test accuracy for 80:20 split: {test_accuracy_80_20_ada:.2f}%\")\n",
    "print(f\"AdaBoost Train accuracy for 70:30 split: {train_accuracy_70_30_ada:.2f}%\")\n",
    "print(f\"AdaBoost Test accuracy for 70:30 split: {test_accuracy_70_30_ada:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd05fc2-09d1-49fc-8977-89a534bb0f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for 80:20 split using KNN model with k=1:\n",
      "Training Accuracy: 99.69%\n",
      "Testing Accuracy: 90.00%\n",
      "\n",
      "Best accuracy for 70:30 split using KNN model with k=1:\n",
      "Training Accuracy: 99.64%\n",
      "Testing Accuracy: 88.33%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Split the dataset into X (features) and y (target variable)\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encoding categorical features to numerical values\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Encoding the target variable\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Define the range of k values to test\n",
    "k_values = range(1, 21)\n",
    "\n",
    "# Perform both 80:20 and 70:30 train-test splits\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize variables to store the best k, training, and testing accuracy for each split\n",
    "best_k_80_20, best_train_accuracy_80_20, best_test_accuracy_80_20 = 0, 0, 0\n",
    "best_k_70_30, best_train_accuracy_70_30, best_test_accuracy_70_30 = 0, 0, 0\n",
    "\n",
    "# Iterate over each k value, train the model, and evaluate training and testing accuracy for both splits\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # 80:20 split accuracies\n",
    "    knn.fit(X_train_80, y_train_80)\n",
    "    train_accuracy_80_20 = accuracy_score(y_train_80, knn.predict(X_train_80)) * 100\n",
    "    test_accuracy_80_20 = accuracy_score(y_test_80, knn.predict(X_test_80)) * 100\n",
    "    if test_accuracy_80_20 > best_test_accuracy_80_20:\n",
    "        best_k_80_20 = k\n",
    "        best_train_accuracy_80_20 = train_accuracy_80_20\n",
    "        best_test_accuracy_80_20 = test_accuracy_80_20\n",
    "    \n",
    "    # 70:30 split accuracies\n",
    "    knn.fit(X_train_70, y_train_70)\n",
    "    train_accuracy_70_30 = accuracy_score(y_train_70, knn.predict(X_train_70)) * 100\n",
    "    test_accuracy_70_30 = accuracy_score(y_test_70, knn.predict(X_test_70)) * 100\n",
    "    if test_accuracy_70_30 > best_test_accuracy_70_30:\n",
    "        best_k_70_30 = k\n",
    "        best_train_accuracy_70_30 = train_accuracy_70_30\n",
    "        best_test_accuracy_70_30 = test_accuracy_70_30\n",
    "\n",
    "# Display the best results for each split\n",
    "print(f\"Best accuracy for 80:20 split using KNN model with k={best_k_80_20}:\")\n",
    "print(f\"Training Accuracy: {best_train_accuracy_80_20:.2f}%\")\n",
    "print(f\"Testing Accuracy: {best_test_accuracy_80_20:.2f}%\\n\")\n",
    "\n",
    "print(f\"Best accuracy for 70:30 split using KNN model with k={best_k_70_30}:\")\n",
    "print(f\"Training Accuracy: {best_train_accuracy_70_30:.2f}%\")\n",
    "print(f\"Testing Accuracy: {best_test_accuracy_70_30:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5216748a-2c06-4a1c-8518-dc73204c63d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.69%\n",
      "Testing Accuracy: 98.75%\n",
      "\n",
      "Training Accuracy: 99.64%\n",
      "Testing Accuracy: 98.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load and encode data\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encoding categorical features to numerical values\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Split data for 80:20 and 70:30 ratios\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the Decision Tree classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 80:20 split evaluation\n",
    "dt_clf.fit(X_train_80, y_train_80)\n",
    "train_accuracy_80_20 = accuracy_score(y_train_80, dt_clf.predict(X_train_80)) * 100\n",
    "test_accuracy_80_20 = accuracy_score(y_test_80, dt_clf.predict(X_test_80)) * 100\n",
    "\n",
    "# 70:30 split evaluation\n",
    "dt_clf.fit(X_train_70, y_train_70)\n",
    "train_accuracy_70_30 = accuracy_score(y_train_70, dt_clf.predict(X_train_70)) * 100\n",
    "test_accuracy_70_30 = accuracy_score(y_test_70, dt_clf.predict(X_test_70)) * 100\n",
    "print(f\"Training Accuracy: {train_accuracy_80_20:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_80_20:.2f}%\\n\")\n",
    "\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy_70_30:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_70_30:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "558ff04b-73ea-442d-abfe-5f42728a0a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.69%\n",
      "Testing Accuracy: 98.75%\n",
      "\n",
      "Training Accuracy: 99.64%\n",
      "Testing Accuracy: 99.17%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load and encode data\n",
    "file_path ='C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encoding categorical features to numerical values\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Define the random forest classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform both 80:20 and 70:30 train-test splits\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# 80:20 split evaluation\n",
    "rf_clf.fit(X_train_80, y_train_80)\n",
    "train_accuracy_80_20 = accuracy_score(y_train_80, rf_clf.predict(X_train_80)) * 100\n",
    "test_accuracy_80_20 = accuracy_score(y_test_80, rf_clf.predict(X_test_80)) * 100\n",
    "\n",
    "# 70:30 split evaluation\n",
    "rf_clf.fit(X_train_70, y_train_70)\n",
    "train_accuracy_70_30 = accuracy_score(y_train_70, rf_clf.predict(X_train_70)) * 100\n",
    "test_accuracy_70_30 = accuracy_score(y_test_70, rf_clf.predict(X_test_70)) * 100\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy_80_20:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_80_20:.2f}%\\n\")\n",
    "\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy_70_30:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_70_30:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b8df9c-0e83-4a88-9c84-03aee18d9b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy for 80:20 split:\n",
      "Training Accuracy: 98.75%\n",
      "Testing Accuracy: 97.50%\n",
      "\n",
      "Logistic Regression accuracy for 70:30 split:\n",
      "Training Accuracy: 98.21%\n",
      "Testing Accuracy: 97.50%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "# Suppress ConvergenceWarnings from Logistic Regression\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Split the dataset into X (features) and y (target variable)\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encoding categorical features to numerical values\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Encoding the target variable\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Perform both 80:20 and 70:30 train-test splits\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=500, random_state=42)\n",
    "\n",
    "# 80:20 split accuracies\n",
    "log_reg.fit(X_train_80, y_train_80)\n",
    "train_accuracy_80_20 = accuracy_score(y_train_80, log_reg.predict(X_train_80)) * 100\n",
    "test_accuracy_80_20 = accuracy_score(y_test_80, log_reg.predict(X_test_80)) * 100\n",
    "\n",
    "# 70:30 split accuracies\n",
    "log_reg.fit(X_train_70, y_train_70)\n",
    "train_accuracy_70_30 = accuracy_score(y_train_70, log_reg.predict(X_train_70)) * 100\n",
    "test_accuracy_70_30 = accuracy_score(y_test_70, log_reg.predict(X_test_70)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Logistic Regression accuracy for 80:20 split:\")\n",
    "print(f\"Training Accuracy: {train_accuracy_80_20:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_80_20:.2f}%\\n\")\n",
    "\n",
    "print(f\"Logistic Regression accuracy for 70:30 split:\")\n",
    "print(f\"Training Accuracy: {train_accuracy_70_30:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_70_30:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "536662d2-83a8-478d-be6d-93044117c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy for 80:20 split:\n",
      "Training Accuracy: 98.12%\n",
      "Testing Accuracy: 96.25%\n",
      "\n",
      "Naive Bayes accuracy for 70:30 split:\n",
      "Training Accuracy: 98.21%\n",
      "Testing Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Split the dataset into X (features) and y (target variable)\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encoding categorical features to numerical values\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Encoding the target variable\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Perform both 80:20 and 70:30 train-test splits\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# 80:20 split accuracies\n",
    "nb_model.fit(X_train_80, y_train_80)\n",
    "train_accuracy_80_20 = accuracy_score(y_train_80, nb_model.predict(X_train_80)) * 100\n",
    "test_accuracy_80_20 = accuracy_score(y_test_80, nb_model.predict(X_test_80)) * 100\n",
    "\n",
    "# 70:30 split accuracies\n",
    "nb_model.fit(X_train_70, y_train_70)\n",
    "train_accuracy_70_30 = accuracy_score(y_train_70, nb_model.predict(X_train_70)) * 100\n",
    "test_accuracy_70_30 = accuracy_score(y_test_70, nb_model.predict(X_test_70)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Naive Bayes accuracy for 80:20 split:\")\n",
    "print(f\"Training Accuracy: {train_accuracy_80_20:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_80_20:.2f}%\\n\")\n",
    "\n",
    "print(f\"Naive Bayes accuracy for 70:30 split:\")\n",
    "print(f\"Training Accuracy: {train_accuracy_70_30:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_70_30:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77090362-1ef5-4824-8c73-51f4ecca7aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Algorithm  Training Accuracy (80:20)  Testing Accuracy (80:20)  \\\n",
      "0        Decision Tree                  99.686520                     98.75   \n",
      "1  K-Nearest Neighbors                  86.833856                     81.25   \n",
      "2  Logistic Regression                  98.746082                     97.50   \n",
      "3        Random Forest                  99.686520                     98.75   \n",
      "4             AdaBoost                  74.608150                     72.50   \n",
      "5          Naive Bayes                  98.119122                     96.25   \n",
      "\n",
      "   Training Accuracy (70:30)  Testing Accuracy (70:30)  \n",
      "0                  99.641577                 98.333333  \n",
      "1                  85.304659                 80.833333  \n",
      "2                  98.207885                 97.500000  \n",
      "3                  99.641577                 99.166667  \n",
      "4                  72.759857                 75.833333  \n",
      "5                  98.207885                 96.666667  \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.exceptions import ConvergenceWarning  # Import ConvergenceWarning\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Load and encode data\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encode categorical features and target\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Perform both 80:20 and 70:30 train-test splits\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each model using both 80:20 and 70:30 splits\n",
    "for model_name, model in models.items():\n",
    "    # 80:20 split\n",
    "    model.fit(X_train_80, y_train_80)\n",
    "    train_accuracy_80_20 = accuracy_score(y_train_80, model.predict(X_train_80)) * 100\n",
    "    test_accuracy_80_20 = accuracy_score(y_test_80, model.predict(X_test_80)) * 100\n",
    "\n",
    "    # 70:30 split\n",
    "    model.fit(X_train_70, y_train_70)\n",
    "    train_accuracy_70_30 = accuracy_score(y_train_70, model.predict(X_train_70)) * 100\n",
    "    test_accuracy_70_30 = accuracy_score(y_test_70, model.predict(X_test_70)) * 100\n",
    "\n",
    "    # Append the results\n",
    "    results.append({\n",
    "        \"Algorithm\": model_name,\n",
    "        \"Training Accuracy (80:20)\": train_accuracy_80_20,\n",
    "        \"Testing Accuracy (80:20)\": test_accuracy_80_20,\n",
    "        \"Training Accuracy (70:30)\": train_accuracy_70_30,\n",
    "        \"Testing Accuracy (70:30)\": test_accuracy_70_30\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame and display it\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd8d9c83-cb67-4d47-96db-c7e1449b8e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best Cross-Validated Score: 0.9811614647622408\n",
      "Training Accuracy: 99.37304075235109\n",
      "Testing Accuracy: 98.75\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare data\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encode categorical features and target\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Perform 80:20 train-test split\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with Random Forest and parameter grid, using StratifiedKFold with 3 splits\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=3),  # Use 3-fold cross-validation to avoid the warning\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV using the 80:20 training data split\n",
    "grid_search.fit(X_train_80, y_train_80)\n",
    "\n",
    "# Get the best parameters and accuracy from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the best model on the full 80:20 training data and test it\n",
    "best_model = grid_search.best_estimator_\n",
    "train_accuracy = accuracy_score(y_train_80, best_model.predict(X_train_80)) * 100\n",
    "test_accuracy = accuracy_score(y_test_80, best_model.predict(X_test_80)) * 100\n",
    "\n",
    "# Print results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validated Score:\", best_score)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe88e575-a7c6-425f-92b9-200d6f677777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrained Model - Training Accuracy: 98.7460815047022\n",
      "Retrained Model - Testing Accuracy: 98.75\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare data\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encode categorical features and target\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Perform 80:20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Best parameters from previous GridSearchCV\n",
    "best_params = {\n",
    "    'n_estimators': 100,   # Example: replace with grid_search.best_params_['n_estimators']\n",
    "    'max_depth': 20,       # Example: replace with grid_search.best_params_['max_depth']\n",
    "    'min_samples_split': 5,# Example: replace with grid_search.best_params_['min_samples_split']\n",
    "    'min_samples_leaf': 2  # Example: replace with grid_search.best_params_['min_samples_leaf']\n",
    "}\n",
    "\n",
    "# Initialize and train a new RandomForestClassifier with best parameters\n",
    "best_model = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    **best_params\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the retrained model on both training and test sets\n",
    "train_accuracy = accuracy_score(y_train, best_model.predict(X_train)) * 100\n",
    "test_accuracy = accuracy_score(y_test, best_model.predict(X_test)) * 100\n",
    "\n",
    "# Print retrained model results\n",
    "print(\"Retrained Model - Training Accuracy:\", train_accuracy)\n",
    "print(\"Retrained Model - Testing Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544fb69-e53b-4c78-953f-fd256086843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6145c-ba6d-4384-b5af-aec7bf82a9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562477d8-fa51-4297-8bcd-fa4c9814bb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff140e-09e3-4d88-b4ef-facd4f1f9088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb77831-fb56-4257-8a72-6531f0bde26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "592dae25-e445-4df5-a551-972089714bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrained Model - Training Accuracy: 98.7460815047022\n",
      "Retrained Model - Testing Accuracy: 98.75\n",
      "Model saved to retrained_random_forest_model.pkl\n",
      "Loaded Model - Testing Accuracy: 98.75\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "import pickle  # Import pickle for saving the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare data\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encode categorical features and target\n",
    "X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Perform 80:20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Best parameters from previous GridSearchCV (replace these with the actual best parameters found)\n",
    "best_params = {\n",
    "    'n_estimators': 100,   # Example: replace with grid_search.best_params_['n_estimators']\n",
    "    'max_depth': 20,       # Example: replace with grid_search.best_params_['max_depth']\n",
    "    'min_samples_split': 5,# Example: replace with grid_search.best_params_['min_samples_split']\n",
    "    'min_samples_leaf': 2  # Example: replace with grid_search.best_params_['min_samples_leaf']\n",
    "}\n",
    "\n",
    "# Initialize and train a new RandomForestClassifier with best parameters\n",
    "best_model = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    **best_params\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the retrained model on both training and test sets\n",
    "train_accuracy = accuracy_score(y_train, best_model.predict(X_train)) * 100\n",
    "test_accuracy = accuracy_score(y_test, best_model.predict(X_test)) * 100\n",
    "\n",
    "# Print retrained model results\n",
    "print(\"Retrained Model - Training Accuracy:\", train_accuracy)\n",
    "print(\"Retrained Model - Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Save the retrained model as a pickle file\n",
    "model_path = 'retrained_random_forest_model.pkl'\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Load the model from the pickle file to verify\n",
    "with open(model_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Verify by making predictions with the loaded model (optional)\n",
    "loaded_test_accuracy = accuracy_score(y_test, loaded_model.predict(X_test)) * 100\n",
    "print(\"Loaded Model - Testing Accuracy:\", loaded_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f18f2e6-e566-4b4c-b01a-9244d2d94b70",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'feature1_encoder.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Load each encoder and transform the corresponding column in unseen_data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m unseen_data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 20\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_encoder.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     unseen_data[col] \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mtransform(unseen_data[col])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Predict using the loaded model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'feature1_encoder.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved model\n",
    "model_path = ''\n",
    "with open(model_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Example of unseen data (replace with actual values as per your dataset's features)\n",
    "unseen_data = pd.DataFrame({\n",
    "    'feature1': ['value1'],  # Replace 'feature1', 'value1' with actual feature names and values\n",
    "    'feature2': ['value2'],\n",
    "    'feature3': ['value3'],\n",
    "    # Add all other features here as per your dataset\n",
    "})\n",
    "\n",
    "# Load each encoder and transform the corresponding column in unseen_data\n",
    "for col in unseen_data.columns:\n",
    "    encoder = joblib.load(f\"{col}_encoder.pkl\")\n",
    "    unseen_data[col] = encoder.transform(unseen_data[col])\n",
    "\n",
    "# Predict using the loaded model\n",
    "predictions = loaded_model.predict(unseen_data)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions for unseen data:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66cb559e-b9f5-4fd8-8c61-6e0757e8b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder for Food Product saved as Food Product_encoder.pkl\n",
      "Encoder for Main Ingredient saved as Main Ingredient_encoder.pkl\n",
      "Encoder for Sweetener saved as Sweetener_encoder.pkl\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Fat/Oil_encoder.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, encoder \u001b[38;5;129;01min\u001b[39;00m encoders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     32\u001b[0m     encoder_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_encoder.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 33\u001b[0m     joblib\u001b[38;5;241m.\u001b[39mdump(encoder, encoder_filename)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoder_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Encode target variable\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Fat/Oil_encoder.pkl'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/gunde/OneDrive/Desktop/project/Dataset/food_ingredients_and_allergens(final).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare data\n",
    "X = data.drop(columns=['Prediction'])\n",
    "y = data['Prediction']\n",
    "\n",
    "# Encode categorical features and target, and save encoders for each column\n",
    "encoders = {}\n",
    "X_encoded = X.copy()\n",
    "for col in X.columns:\n",
    "    encoders[col] = LabelEncoder().fit(X[col])\n",
    "    X_encoded[col] = encoders[col].transform(X[col])\n",
    "\n",
    "# Save each encoder as a .pkl file in the current directory\n",
    "for col, encoder in encoders.items():\n",
    "    encoder_filename = f\"{col}_encoder.pkl\"\n",
    "    joblib.dump(encoder, encoder_filename)\n",
    "    print(f\"Encoder for {col} saved as {encoder_filename}\")\n",
    "\n",
    "# Encode target variable\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Perform 80:20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a RandomForestClassifier with the best parameters\n",
    "best_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 20,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2\n",
    "}\n",
    "\n",
    "best_model = RandomForestClassifier(random_state=42, **best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, best_model.predict(X_train)) * 100\n",
    "test_accuracy = accuracy_score(y_test, best_model.predict(X_test)) * 100\n",
    "\n",
    "print(\"Retrained Model - Training Accuracy:\", train_accuracy)\n",
    "print(\"Retrained Model - Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Save the model\n",
    "model_path = 'retrained_random_forest_model.pkl'\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd063a4-5330-4fb5-bc57-acfeeb2a8438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ec8ec-fb54-4c8a-9ded-074857a83457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb9bb4-0292-4523-afa8-178cf5a30a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
