{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2051478-f667-4737-b3e4-26d40753b62b",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d73629a-ff19-4630-a883-768016df979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba509a2-0897-4453-9983-fad19bef8834",
   "metadata": {},
   "source": [
    "# Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6dda98-6e11-4007-a7e7-4e1ba62605cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Dataset/preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017b6af-6010-4d5d-b21c-4b9bdac28c8a",
   "metadata": {},
   "source": [
    "# Splitting The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39cb31a1-0aa3-4dc3-ac63-991fa7e18ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features variable: (398, 8)\n",
      "Shape of target variable: (398,)\n",
      "\n",
      "Shape of variable in 80:20 split:\n",
      "\tShape of X_train variable: (318, 8)\n",
      "\tShape of X_test variable: (80, 8)\n",
      "\tShape of y_train variable: (318,)\n",
      "\tShape of y_test variable: (80,)\n",
      "\n",
      "Shape of variable in 70:30 split\n",
      "\tShape of X_train variable: (278, 8)\n",
      "\tShape of X_test variable: (120, 8)\n",
      "\tShape of y_train variable: (278,)\n",
      "\tShape of y_test variable: (120,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target variable (if applicable)\n",
    "X = df.drop(columns=['Is_Allergen'])\n",
    "y = df['Is_Allergen']\n",
    "\n",
    "# Shape of features and target variables\n",
    "print(\"Shape of features variable:\",X.shape)\n",
    "print(\"Shape of target variable:\",y.shape)\n",
    "print()\n",
    "\n",
    "# Split the data into train and test sets 80:20 ratio\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the shapes\n",
    "print(\"Shape of variable in 80:20 split:\")\n",
    "print(\"\\tShape of X_train variable:\",X_train_80.shape)\n",
    "print(\"\\tShape of X_test variable:\",X_test_80.shape)\n",
    "print(\"\\tShape of y_train variable:\",y_train_80.shape)\n",
    "print(\"\\tShape of y_test variable:\",y_test_80.shape)\n",
    "print()\n",
    "\n",
    "# Split the data into train and test sets 70:30 ratio\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Displaying the shapes\n",
    "print(\"Shape of variable in 70:30 split\")\n",
    "print(\"\\tShape of X_train variable:\",X_train_70.shape)\n",
    "print(\"\\tShape of X_test variable:\",X_test_70.shape)\n",
    "print(\"\\tShape of y_train variable:\",y_train_70.shape)\n",
    "print(\"\\tShape of y_test variable:\",y_test_70.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27961bd1-ec49-42bf-b7b5-3296eba1c39f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a200c9-d841-4b4e-9dee-92d8a553c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model test accuracy (in %): 61.66666666666667\n",
      "Logistic Regression model train accuracy (in %): 58.63309352517986\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76        87\n",
      "           1       0.07      0.03      0.04        33\n",
      "\n",
      "    accuracy                           0.62       120\n",
      "   macro avg       0.38      0.43      0.40       120\n",
      "weighted avg       0.52      0.62      0.56       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[73 14]\n",
      " [32  1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Applying Scaling on the Dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_70)\n",
    "X_test_scaled = scaler.transform(X_test_70)\n",
    "\n",
    "# LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train_70)\n",
    "\n",
    "# Prediction\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "y_train_pred = lr.predict(X_train_scaled)\n",
    "\n",
    "# Test Accuracy\n",
    "acc = accuracy_score(y_test_70, y_pred)\n",
    "print(\"Logistic Regression model test accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Train Accuracy\n",
    "acc = accuracy_score(y_train_70, y_train_pred)\n",
    "print(\"Logistic Regression model train accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_70, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_70, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3274dd-fd9d-4ff2-a539-f226bef54f96",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d09c6d1-e046-4466-a4fc-9db242960145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model test accuracy (in %): 95.0\n",
      "Decision Tree model train accuracy (in %): 100.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        87\n",
      "           1       0.94      0.88      0.91        33\n",
      "\n",
      "    accuracy                           0.95       120\n",
      "   macro avg       0.95      0.93      0.94       120\n",
      "weighted avg       0.95      0.95      0.95       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85  2]\n",
      " [ 4 29]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Prediction\n",
    "y_pred = dt.predict(X_test_70)\n",
    "y_train_pred = dt.predict(X_train_70)\n",
    "\n",
    "# Test Accuracy\n",
    "acc = accuracy_score(y_test_70, y_pred)\n",
    "print(\"Decision Tree model test accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Train Accuracy\n",
    "acc = accuracy_score(y_train_70, y_train_pred)\n",
    "print(\"Decision Tree model train accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_70, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_70, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce9ca6-933d-4528-a087-f8998dec4272",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc1c719-963c-4c54-81d4-3e73b2ccaa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model test accuracy (in %): 97.5\n",
      "Random Forest model train accuracy (in %): 100.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        87\n",
      "           1       0.97      0.94      0.95        33\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.97      0.96      0.97       120\n",
      "weighted avg       0.97      0.97      0.97       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[86  1]\n",
      " [ 2 31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Prediction\n",
    "y_pred = rf.predict(X_test_70)\n",
    "y_train_pred = rf.predict(X_train_70)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test_70, y_pred)\n",
    "print(\"Random Forest model test accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Train Accuracy\n",
    "acc = accuracy_score(y_train_70, y_train_pred)\n",
    "print(\"Random Forest model train accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_70, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_70, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17937f-6945-416d-a368-ead48fd0b6dd",
   "metadata": {},
   "source": [
    "## Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01190ac-6721-4d28-940e-e9951a3db8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model test accuracy (in %): 98.33333333333333\n",
      "XGBoost model train accuracy (in %): 100.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        87\n",
      "           1       0.94      1.00      0.97        33\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.97      0.99      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85  2]\n",
      " [ 0 33]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Prediction\n",
    "y_pred = xgb.predict(X_test_70)\n",
    "y_train_pred = xgb.predict(X_train_70)\n",
    "\n",
    "# Test Accuracy\n",
    "acc = accuracy_score(y_test_70, y_pred)\n",
    "print(\"XGBoost model test accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Train Accuracy\n",
    "acc = accuracy_score(y_train_70, y_train_pred)\n",
    "print(\"XGBoost model train accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_70, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_70, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b5677-42d7-42e3-89a5-cc50ac2d11f0",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81655362-b2c5-4ceb-b5d6-b7a7a4a5e70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model Test accuracy (in %): 72.5\n",
      "SVM model Train accuracy (in %): 60.431654676258994\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        87\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.72       120\n",
      "   macro avg       0.36      0.50      0.42       120\n",
      "weighted avg       0.53      0.72      0.61       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[87  0]\n",
      " [33  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kishore/anaconda3/envs/SafeBite_AI/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kishore/anaconda3/envs/SafeBite_AI/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kishore/anaconda3/envs/SafeBite_AI/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc = SVC()\n",
    "svc.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Prediction\n",
    "y_pred = svc.predict(X_test_70)\n",
    "y_train_pred = svc.predict(X_train_70)\n",
    "\n",
    "# Test Accuracy\n",
    "acc = accuracy_score(y_test_70, y_pred)\n",
    "print(\"SVM model Test accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Train Accuracy\n",
    "acc = accuracy_score(y_train_70, y_train_pred)\n",
    "print(\"SVM model Train accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_70, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_70, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecfa003-64f8-4e6b-b265-0e36ae3c85a9",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e92fab-a162-479c-b624-7e941427a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model Test accuracy (in %): 62.5\n",
      "KNN model Train accuracy (in %): 72.66187050359713\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.60      0.70        87\n",
      "           1       0.40      0.70      0.51        33\n",
      "\n",
      "    accuracy                           0.62       120\n",
      "   macro avg       0.62      0.65      0.60       120\n",
      "weighted avg       0.72      0.62      0.65       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[52 35]\n",
      " [10 23]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # Optional: adjust n_neighbors as needed\n",
    "knn.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Prediction\n",
    "y_pred = knn.predict(X_test_70)\n",
    "y_train_pred = knn.predict(X_train_70)\n",
    "\n",
    "# Test Accuracy\n",
    "acc = accuracy_score(y_test_70, y_pred)\n",
    "print(\"KNN model Test accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Train Accuracy\n",
    "acc = accuracy_score(y_train_70, y_train_pred)\n",
    "print(\"KNN model Train accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_70, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_70, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27027d-a7cc-411a-a079-6bbaae2371a2",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e125cd78-5294-4bca-9e9a-d99eed9eed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model Test accuracy (in %): 88.33333333333333\n",
      "Naive Bayes model Train accuracy (in %): 89.92805755395683\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91        87\n",
      "           1       0.72      0.94      0.82        33\n",
      "\n",
      "    accuracy                           0.88       120\n",
      "   macro avg       0.85      0.90      0.87       120\n",
      "weighted avg       0.90      0.88      0.89       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[75 12]\n",
      " [ 2 31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Prediction\n",
    "y_pred = nb.predict(X_test_70)\n",
    "y_train_pred = nb.predict(X_train_70)\n",
    "\n",
    "# Test Accuracy\n",
    "acc = accuracy_score(y_test_70, y_pred)\n",
    "print(\"Naive Bayes model Test accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Train Accuracy\n",
    "acc = accuracy_score(y_train_70, y_train_pred)\n",
    "print(\"Naive Bayes model Train accuracy (in %):\", acc * 100)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_70, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_70, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe4d8d-d0be-4338-8d12-aad64272b3a2",
   "metadata": {},
   "source": [
    "# Comparing the Various Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "628f4f2e-71d2-4617-98b8-88998ce880ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison for 80/20 and 70/30 splits:\n",
      "                    Model 80_split_train_accuracy 80_split_test_accuracy  \\\n",
      "0     Logistic Regression                   58.49                  63.75   \n",
      "1           Decision Tree                  100.00                  97.50   \n",
      "2           Random Forest                  100.00                  98.75   \n",
      "3                 XGBoost                  100.00                  97.50   \n",
      "4  Support Vector Machine                   61.95                  72.50   \n",
      "5     K-Nearest Neighbors                   72.64                  70.00   \n",
      "6             Naive Bayes                   90.25                  86.25   \n",
      "\n",
      "  70_split_train_accuracy 70_split_test_accuracy  \n",
      "0                   58.63                  61.67  \n",
      "1                  100.00                  95.83  \n",
      "2                  100.00                  98.33  \n",
      "3                  100.00                  98.33  \n",
      "4                   60.43                  72.50  \n",
      "5                   72.66                  62.50  \n",
      "6                   89.93                  88.33  \n"
     ]
    }
   ],
   "source": [
    "# Define models to test\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {\n",
    "    \"Model\": list(models.keys()),\n",
    "    \"80_split_train_accuracy\": [],\n",
    "    \"80_split_test_accuracy\": [],\n",
    "    \"70_split_train_accuracy\": [],\n",
    "    \"70_split_test_accuracy\": []\n",
    "}\n",
    "\n",
    "# Function to evaluate and store results for a given split\n",
    "def evaluate_models(split_ratio, train_accuracy_col, test_accuracy_col):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_ratio, random_state=42)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)  # Train the model\n",
    "        train_accuracy = accuracy_score(y_train, model.predict(X_train)) * 100 # Train accuracy\n",
    "        test_accuracy = accuracy_score(y_test, model.predict(X_test)) * 100 # Test accuracy\n",
    "        \n",
    "        # Append the results for the specific columns\n",
    "        results[train_accuracy_col].append(f\"{train_accuracy:.2f}\")\n",
    "        results[test_accuracy_col].append(f\"{test_accuracy:.2f}\")\n",
    "\n",
    "# Evaluate models for both 80/20 and 70/30 splits\n",
    "evaluate_models(0.2, \"80_split_train_accuracy\", \"80_split_test_accuracy\")\n",
    "evaluate_models(0.3, \"70_split_train_accuracy\", \"70_split_test_accuracy\")\n",
    "\n",
    "# Convert results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Comparison for 80/20 and 70/30 splits:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b673ea4-1fa2-4742-8a7d-5b98651a7d97",
   "metadata": {},
   "source": [
    "# Finetuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3acd08bc-73c4-4ebe-a80b-e74ddedc8867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters from Randomized Search: {'subsample': 1.0, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.3, 'colsample_bytree': 1.0}\n",
      "Tuned XGBoost model test accuracy (in %): 98.33333333333333\n",
      "Tuned XGBoost model train accuracy (in %): 99.64028776978418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.3, 0.6, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# RandomizedSearchCV with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid,\n",
    "                                   n_iter=50, scoring='accuracy', cv=3, verbose=1, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters from Randomized Search:\", random_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# Predictions with the best model\n",
    "y_pred_best = best_xgb.predict(X_test_70)\n",
    "y_train_pred_best = best_xgb.predict(X_train_70)\n",
    "\n",
    "# Test Accuracy with the best model\n",
    "acc_best = accuracy_score(y_test_70, y_pred_best)\n",
    "print(\"Tuned XGBoost model test accuracy (in %):\", acc_best * 100)\n",
    "\n",
    "# Train Accuracy with the best model\n",
    "acc_best = accuracy_score(y_train_70, y_train_pred_best)\n",
    "print(\"Tuned XGBoost model train accuracy (in %):\", acc_best * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65020733-942c-49e8-ab10-270f0b75caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b51a8a-2ffa-4701-982f-1499cd92362f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Model/Allergen_detection.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Save the XGBoost model with joblib\n",
    "joblib.dump(best_xgb, '../Model/Allergen_detection.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597fb63-c2c7-4b3d-80ee-83e6df3fd973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
