{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946bc85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65b4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'E:/my files/project/food-allergen/Allergen_Status_of_Food_Products.csv'  \n",
    "data = pd.read_csv(file_path, keep_default_na=False, na_values=\"\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train, test = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad10391c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Product</th>\n",
       "      <th>Main Ingredient</th>\n",
       "      <th>Sweetener</th>\n",
       "      <th>Fat/Oil</th>\n",
       "      <th>Seasoning</th>\n",
       "      <th>Allergens</th>\n",
       "      <th>Price ($)</th>\n",
       "      <th>Customer rating (Out of 5)</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Gulab Jamun</td>\n",
       "      <td>Milk solids</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Ghee</td>\n",
       "      <td>Cardamom syrup</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>5.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Roasted Brussels Sprouts</td>\n",
       "      <td>Brussels sprouts</td>\n",
       "      <td>None</td>\n",
       "      <td>Olive oil</td>\n",
       "      <td>Balsamic glaze</td>\n",
       "      <td>None</td>\n",
       "      <td>13.61</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Does not contain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Rice Pudding</td>\n",
       "      <td>Rice</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Cinnamon, raisins</td>\n",
       "      <td>Rice, Dairy</td>\n",
       "      <td>16.09</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Apple Pie</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Cinnamon, pastry</td>\n",
       "      <td>Wheat, Dairy</td>\n",
       "      <td>18.70</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Cinnamon Rolls</td>\n",
       "      <td>Dough</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Cinnamon, icing</td>\n",
       "      <td>Wheat, Dairy</td>\n",
       "      <td>7.93</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Quinoa Stuffed Peppers</td>\n",
       "      <td>Quinoa</td>\n",
       "      <td>None</td>\n",
       "      <td>Olive oil</td>\n",
       "      <td>Vegetables, spices</td>\n",
       "      <td>None</td>\n",
       "      <td>11.91</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Does not contain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Stuffed Mushrooms</td>\n",
       "      <td>Mushrooms</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Garlic, herbs</td>\n",
       "      <td>None</td>\n",
       "      <td>19.36</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Does not contain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Almond Cookies</td>\n",
       "      <td>Almonds</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Flour</td>\n",
       "      <td>Almonds, Wheat, Dairy</td>\n",
       "      <td>10.15</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Sweet Potato Casserole</td>\n",
       "      <td>Sweet potatoes</td>\n",
       "      <td>Brown sugar</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Cinnamon, nutmeg</td>\n",
       "      <td>Dairy, Nuts</td>\n",
       "      <td>13.47</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Pesto Chicken</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>None</td>\n",
       "      <td>Pesto sauce</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.29</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Does not contain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Food Product   Main Ingredient    Sweetener      Fat/Oil  \\\n",
       "83                Gulab Jamun       Milk solids        Sugar         Ghee   \n",
       "227  Roasted Brussels Sprouts  Brussels sprouts         None    Olive oil   \n",
       "284              Rice Pudding              Rice        Sugar         Milk   \n",
       "382                 Apple Pie            Apples        Sugar       Butter   \n",
       "355            Cinnamon Rolls             Dough        Sugar       Butter   \n",
       "..                        ...               ...          ...          ...   \n",
       "186    Quinoa Stuffed Peppers            Quinoa         None    Olive oil   \n",
       "181         Stuffed Mushrooms         Mushrooms         None         None   \n",
       "0              Almond Cookies           Almonds        Sugar       Butter   \n",
       "92     Sweet Potato Casserole    Sweet potatoes  Brown sugar       Butter   \n",
       "178             Pesto Chicken           Chicken         None  Pesto sauce   \n",
       "\n",
       "              Seasoning              Allergens  Price ($)  \\\n",
       "83       Cardamom syrup                  Dairy       5.94   \n",
       "227      Balsamic glaze                   None      13.61   \n",
       "284   Cinnamon, raisins            Rice, Dairy      16.09   \n",
       "382    Cinnamon, pastry           Wheat, Dairy      18.70   \n",
       "355     Cinnamon, icing           Wheat, Dairy       7.93   \n",
       "..                  ...                    ...        ...   \n",
       "186  Vegetables, spices                   None      11.91   \n",
       "181       Garlic, herbs                   None      19.36   \n",
       "0                 Flour  Almonds, Wheat, Dairy      10.15   \n",
       "92     Cinnamon, nutmeg            Dairy, Nuts      13.47   \n",
       "178                None                   None       8.29   \n",
       "\n",
       "     Customer rating (Out of 5)        Prediction  \n",
       "83                          4.0          Contains  \n",
       "227                         4.7  Does not contain  \n",
       "284                         3.8          Contains  \n",
       "382                         1.8          Contains  \n",
       "355                         3.8          Contains  \n",
       "..                          ...               ...  \n",
       "186                         3.5  Does not contain  \n",
       "181                         1.8  Does not contain  \n",
       "0                           3.1          Contains  \n",
       "92                          2.6          Contains  \n",
       "178                         4.9  Does not contain  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7211a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the training set\n",
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea58539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the 'Prediction' column to numerical values\n",
    "train['Prediction'] = train['Prediction'].map({'Contains': 1, 'Does not contain': 0})\n",
    "test['Prediction'] = test['Prediction'].map({'Contains': 1, 'Does not contain': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affbef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns in the training set\n",
    "categorical_columns_train = train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize and fit the Leave-One-Out Encoder on the training data\n",
    "encoder = LeaveOneOutEncoder(cols=categorical_columns_train)\n",
    "train_encoded = encoder.fit_transform(train[categorical_columns_train], train['Price ($)'])\n",
    "test_encoded = encoder.transform(test[categorical_columns_train])\n",
    "\n",
    "# Add the encoded columns to the training and test data\n",
    "train = pd.concat([train.drop(categorical_columns_train, axis=1), train_encoded], axis=1)\n",
    "test = pd.concat([test.drop(categorical_columns_train, axis=1), test_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d58d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price ($)</th>\n",
       "      <th>Customer rating (Out of 5)</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Food Product</th>\n",
       "      <th>Main Ingredient</th>\n",
       "      <th>Sweetener</th>\n",
       "      <th>Fat/Oil</th>\n",
       "      <th>Seasoning</th>\n",
       "      <th>Allergens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>11.997581</td>\n",
       "      <td>11.952381</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.163016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>13.61</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>11.475000</td>\n",
       "      <td>12.350507</td>\n",
       "      <td>13.463231</td>\n",
       "      <td>11.475000</td>\n",
       "      <td>12.116348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>16.09</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>7.695000</td>\n",
       "      <td>11.997581</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.305671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>18.70</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>12.185000</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>11.997581</td>\n",
       "      <td>12.261864</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.575385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>7.93</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>16.280000</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>11.997581</td>\n",
       "      <td>12.261864</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.575385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>11.91</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>14.685000</td>\n",
       "      <td>12.350507</td>\n",
       "      <td>13.463231</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.116348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>19.36</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.087500</td>\n",
       "      <td>12.350507</td>\n",
       "      <td>11.834762</td>\n",
       "      <td>8.646667</td>\n",
       "      <td>12.116348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.15</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>11.997581</td>\n",
       "      <td>12.261864</td>\n",
       "      <td>12.225000</td>\n",
       "      <td>12.305671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>13.47</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>12.261864</td>\n",
       "      <td>12.305671</td>\n",
       "      <td>12.305671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>8.29</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>12.570000</td>\n",
       "      <td>11.434762</td>\n",
       "      <td>12.350507</td>\n",
       "      <td>8.685000</td>\n",
       "      <td>12.947000</td>\n",
       "      <td>12.116348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price ($)  Customer rating (Out of 5)  Prediction  Food Product  \\\n",
       "83        5.94                         4.0           1     12.305671   \n",
       "227      13.61                         4.7           0     12.305671   \n",
       "284      16.09                         3.8           1     12.305671   \n",
       "382      18.70                         1.8           1     12.185000   \n",
       "355       7.93                         3.8           1     16.280000   \n",
       "..         ...                         ...         ...           ...   \n",
       "186      11.91                         3.5           0     12.305671   \n",
       "181      19.36                         1.8           0     12.305671   \n",
       "0        10.15                         3.1           1     12.305671   \n",
       "92       13.47                         2.6           1     12.305671   \n",
       "178       8.29                         4.9           0     12.570000   \n",
       "\n",
       "     Main Ingredient  Sweetener    Fat/Oil  Seasoning  Allergens  \n",
       "83         12.305671  11.997581  11.952381  12.305671  12.163016  \n",
       "227        11.475000  12.350507  13.463231  11.475000  12.116348  \n",
       "284         7.695000  11.997581  11.950000  12.305671  12.305671  \n",
       "382        11.550000  11.997581  12.261864  12.305671  12.575385  \n",
       "355        12.305671  11.997581  12.261864  12.305671  12.575385  \n",
       "..               ...        ...        ...        ...        ...  \n",
       "186        14.685000  12.350507  13.463231  12.305671  12.116348  \n",
       "181        12.087500  12.350507  11.834762   8.646667  12.116348  \n",
       "0          12.305671  11.997581  12.261864  12.225000  12.305671  \n",
       "92         12.305671  14.300000  12.261864  12.305671  12.305671  \n",
       "178        11.434762  12.350507   8.685000  12.947000  12.116348  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce51eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target variable\n",
    "X_train = train.drop(['Prediction'], axis=1)\n",
    "y_train = train['Prediction']\n",
    "X_test = test.drop(['Prediction'], axis=1)\n",
    "y_test = test['Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ad79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of models\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('model', LogisticRegression(max_iter=1000))\n",
    "    ]),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Support Vector Classifier\": Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('model', SVC(probability=True))\n",
    "    ]),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"XGBoost\": XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a169ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results in a dictionary\n",
    "results = {}\n",
    "confusion_matrices_train = {}\n",
    "confusion_matrices_test = {}\n",
    "\n",
    "# Evaluate each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd9ab258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\anaconda3\\envs\\food-allergen-detection\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sudha\\anaconda3\\envs\\food-allergen-detection\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sudha\\anaconda3\\envs\\food-allergen-detection\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sudha\\anaconda3\\envs\\food-allergen-detection\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sudha\\anaconda3\\envs\\food-allergen-detection\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sudha\\anaconda3\\envs\\food-allergen-detection\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    # Perform cross-validation for a more reliable performance estimate\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy for train and test\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Get classification reports for train and test sets\n",
    "    train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "    test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "    \n",
    "    # Get confusion matrices for train and test sets\n",
    "    train_confusion = confusion_matrix(y_train, y_train_pred)\n",
    "    test_confusion = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    # Store confusion matrices in dictionaries\n",
    "    confusion_matrices_train[model_name] = pd.DataFrame(train_confusion, \n",
    "                                                        index=[f\"Actual_{i}\" for i in range(len(train_confusion))], \n",
    "                                                        columns=[f\"Predicted_{i}\" for i in range(len(train_confusion))])\n",
    "    \n",
    "    confusion_matrices_test[model_name] = pd.DataFrame(test_confusion, \n",
    "                                                       index=[f\"Actual_{i}\" for i in range(len(test_confusion))], \n",
    "                                                       columns=[f\"Predicted_{i}\" for i in range(len(test_confusion))])\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        \"Cross-Validation Mean Accuracy\": cv_scores.mean(),\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy,\n",
    "        \"Train Precision\": train_report['weighted avg']['precision'],\n",
    "        \"Test Precision\": test_report['weighted avg']['precision'],\n",
    "        \"Train Recall\": train_report['weighted avg']['recall'],\n",
    "        \"Test Recall\": test_report['weighted avg']['recall'],\n",
    "        \"Train F1-Score\": train_report['weighted avg']['f1-score'],\n",
    "        \"Test F1-Score\": test_report['weighted avg']['f1-score']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9b227ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-Validation Mean Accuracy</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Train F1-Score</th>\n",
       "      <th>Test F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.563729</td>\n",
       "      <td>0.597315</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.513528</td>\n",
       "      <td>0.444388</td>\n",
       "      <td>0.597315</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.527879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.587514</td>\n",
       "      <td>0.768456</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.765465</td>\n",
       "      <td>0.513717</td>\n",
       "      <td>0.768456</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.766225</td>\n",
       "      <td>0.511815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.916328</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.879209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.909492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <td>0.661299</td>\n",
       "      <td>0.785235</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.782054</td>\n",
       "      <td>0.622436</td>\n",
       "      <td>0.785235</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.781196</td>\n",
       "      <td>0.628276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.929661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.774910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.926271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.762651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.762065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Cross-Validation Mean Accuracy  Train Accuracy  \\\n",
       "Logistic Regression                              0.563729        0.597315   \n",
       "KNN                                              0.587514        0.768456   \n",
       "Decision Tree                                    0.916328        1.000000   \n",
       "Random Forest                                    0.879209        1.000000   \n",
       "Gradient Boosting                                0.909492        1.000000   \n",
       "Support Vector Classifier                        0.661299        0.785235   \n",
       "AdaBoost                                         0.929661        1.000000   \n",
       "XGBoost                                          0.926271        1.000000   \n",
       "\n",
       "                           Test Accuracy  Train Precision  Test Precision  \\\n",
       "Logistic Regression                 0.65         0.513528        0.444388   \n",
       "KNN                                 0.51         0.765465        0.513717   \n",
       "Decision Tree                       0.76         1.000000        0.754094   \n",
       "Random Forest                       0.83         1.000000        0.845167   \n",
       "Gradient Boosting                   0.72         1.000000        0.709528   \n",
       "Support Vector Classifier           0.65         0.782054        0.622436   \n",
       "AdaBoost                            0.78         1.000000        0.774910   \n",
       "XGBoost                             0.77         1.000000        0.762651   \n",
       "\n",
       "                           Train Recall  Test Recall  Train F1-Score  \\\n",
       "Logistic Regression            0.597315         0.65        0.513725   \n",
       "KNN                            0.768456         0.51        0.766225   \n",
       "Decision Tree                  1.000000         0.76        1.000000   \n",
       "Random Forest                  1.000000         0.83        1.000000   \n",
       "Gradient Boosting              1.000000         0.72        1.000000   \n",
       "Support Vector Classifier      0.785235         0.65        0.781196   \n",
       "AdaBoost                       1.000000         0.78        1.000000   \n",
       "XGBoost                        1.000000         0.77        1.000000   \n",
       "\n",
       "                           Test F1-Score  \n",
       "Logistic Regression             0.527879  \n",
       "KNN                             0.511815  \n",
       "Decision Tree                   0.755736  \n",
       "Random Forest                   0.833466  \n",
       "Gradient Boosting               0.712000  \n",
       "Support Vector Classifier       0.628276  \n",
       "AdaBoost                        0.776092  \n",
       "XGBoost                         0.762065  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to a DataFrame for easier viewing\n",
    "result_df = pd.DataFrame(results).T\n",
    "\n",
    "# Display the results\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c7557d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudha\\anaconda3\\envs\\food-allergen-detection\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70ba417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9697986577181208\n",
      "Test Accuracy: 0.83\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75        33\n",
      "           1       0.89      0.85      0.87        67\n",
      "\n",
      "    accuracy                           0.83       100\n",
      "   macro avg       0.81      0.82      0.81       100\n",
      "weighted avg       0.84      0.83      0.83       100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26  7]\n",
      " [10 57]]\n",
      "Cross-Validation Accuracy:  0.8691525423728814\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest model with the best parameters\n",
    "final_model = RandomForestClassifier(\n",
    "    max_depth=7,                \n",
    "    max_features='log2',        \n",
    "    min_samples_leaf=5,         \n",
    "    min_samples_split=10,      \n",
    "    n_estimators=100,        \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the entire training dataset\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_train_pred = final_model.predict(X_train)\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Train Accuracy:\",train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "cv_scores = cross_val_score(final_model, X_train, y_train, cv=5)\n",
    "print(\"Cross-Validation Accuracy: \", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107a2c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and encoder have been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained Random Forest model\n",
    "joblib.dump(final_model, 'random_forest_model_updated.pkl')\n",
    "\n",
    "# Save the fitted Leave-One-Out Encoder\n",
    "joblib.dump(encoder, 'leave_one_out_encoder_updated.pkl')\n",
    "\n",
    "print(\"Model and encoder have been saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1731375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "                       Feature  Importance\n",
      "7                   Allergens    0.595914\n",
      "5                     Fat/Oil    0.133250\n",
      "4                   Sweetener    0.098956\n",
      "0                   Price ($)    0.047962\n",
      "1  Customer rating (Out of 5)    0.040581\n",
      "6                   Seasoning    0.033310\n",
      "3             Main Ingredient    0.031740\n",
      "2                Food Product    0.018288\n"
     ]
    }
   ],
   "source": [
    "feature_importances = final_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importances:\\n\", importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1d974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
