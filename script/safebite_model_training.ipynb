{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a43f1c-d7a7-44c8-bfa8-dc2fba13a144",
   "metadata": {},
   "source": [
    "## Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f70d3d9-ba1e-4bd9-9f20-f1ce1e899798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5cb666-12be-493b-b765-bda988354b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/Admin/Desktop/food_allergen_detection/dataset/output_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9a94a6-90c8-40ce-bbad-cabc8b756be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Customer rating</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Food Product</th>\n",
       "      <th>Main Ingredient</th>\n",
       "      <th>Sweetener</th>\n",
       "      <th>Fat/Oil</th>\n",
       "      <th>Seasoning</th>\n",
       "      <th>Allergens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.15</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.170000</td>\n",
       "      <td>6.170</td>\n",
       "      <td>12.343736</td>\n",
       "      <td>12.471786</td>\n",
       "      <td>13.408</td>\n",
       "      <td>6.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.17</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10.150000</td>\n",
       "      <td>10.150</td>\n",
       "      <td>12.387473</td>\n",
       "      <td>12.519167</td>\n",
       "      <td>13.806</td>\n",
       "      <td>10.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.65</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>17.480</td>\n",
       "      <td>12.371511</td>\n",
       "      <td>12.031228</td>\n",
       "      <td>11.584</td>\n",
       "      <td>17.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.48</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>13.223333</td>\n",
       "      <td>19.650</td>\n",
       "      <td>12.379317</td>\n",
       "      <td>12.069298</td>\n",
       "      <td>11.801</td>\n",
       "      <td>19.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.83</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>12.397588</td>\n",
       "      <td>17.925</td>\n",
       "      <td>12.403237</td>\n",
       "      <td>12.185965</td>\n",
       "      <td>12.466</td>\n",
       "      <td>12.072073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Customer rating  Prediction  Food Product  Main Ingredient  \\\n",
       "0  10.15              3.1           0      6.170000            6.170   \n",
       "1   6.17              4.5           0     10.150000           10.150   \n",
       "2  19.65              4.1           0     12.500000           17.480   \n",
       "3  17.48              4.7           0     13.223333           19.650   \n",
       "4  10.83              3.7           0     12.397588           17.925   \n",
       "\n",
       "   Sweetener    Fat/Oil  Seasoning  Allergens  \n",
       "0  12.343736  12.471786     13.408   6.170000  \n",
       "1  12.387473  12.519167     13.806  10.150000  \n",
       "2  12.371511  12.031228     11.584  17.480000  \n",
       "3  12.379317  12.069298     11.801  19.650000  \n",
       "4  12.403237  12.185965     12.466  12.072073  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be2f5b4-88b2-4eb8-b3e7-f4a4aac04951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target = 'Prediction'\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4687a1-7bbf-4565-b189-47d65f1d3586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (X): (398, 8)\n",
      "Shape of target (y): (398,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X and y\n",
    "print(\"Shape of features (X):\", X.shape)\n",
    "print(\"Shape of target (y):\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649df989-f043-42f5-af3f-8536f20c52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and testing sets in 70:30 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dcf4e1b-bd4f-4cff-ba4b-69a6f55e9c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (278, 8)\n",
      "Shape of X_test: (120, 8)\n",
      "Shape of y_train: (278,)\n",
      "Shape of y_test: (120,)\n"
     ]
    }
   ],
   "source": [
    "#Printing the shapes of the resulting datasets\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33618e7-a377-4906-9765-ed4e42e0354f",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8bee4c8-9c43-421c-bce6-1a3849497302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58edffae-6e2a-42b2-904a-0fe94e184073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76        87\n",
      "           1       0.07      0.03      0.04        33\n",
      "\n",
      "    accuracy                           0.62       120\n",
      "   macro avg       0.38      0.43      0.40       120\n",
      "weighted avg       0.52      0.62      0.56       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[73 14]\n",
      " [32  1]]\n",
      "\n",
      "\n",
      "--- Decision Tree ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        87\n",
      "           1       0.94      0.97      0.96        33\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.96      0.97      0.97       120\n",
      "weighted avg       0.98      0.97      0.98       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85  2]\n",
      " [ 1 32]]\n",
      "\n",
      "\n",
      "--- Random Forest ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        87\n",
      "           1       0.97      0.97      0.97        33\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.98      0.98      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[86  1]\n",
      " [ 1 32]]\n",
      "\n",
      "\n",
      "--- AdaBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\safebite\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        87\n",
      "           1       0.97      0.97      0.97        33\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.98      0.98      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[86  1]\n",
      " [ 1 32]]\n",
      "\n",
      "\n",
      "--- Naive Bayes ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91        87\n",
      "           1       0.72      0.94      0.82        33\n",
      "\n",
      "    accuracy                           0.88       120\n",
      "   macro avg       0.85      0.90      0.87       120\n",
      "weighted avg       0.90      0.88      0.89       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[75 12]\n",
      " [ 2 31]]\n",
      "\n",
      "\n",
      "--- XGBoost ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        87\n",
      "           1       0.94      1.00      0.97        33\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.97      0.99      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85  2]\n",
      " [ 0 33]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\safebite\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:37:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "              ('scaler',StandardScaler()),\n",
    "              ('model',LogisticRegression(max_iter=1000))\n",
    "               ]),  \n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'XGBoost': xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"--- {model_name} ---\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    \n",
    "    # Compute accuracies\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    overall_accuracy = (train_accuracy * len(y_train) + test_accuracy * len(y_test)) / (len(y_train) + len(y_test))\n",
    "\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Training Accuracy': train_accuracy,\n",
    "        'Testing Accuracy': test_accuracy,\n",
    "        'Overall Accuracy': overall_accuracy\n",
    "    })\n",
    "    \n",
    "    # Print classification report and confusion matrix\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, test_preds))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, test_preds))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Create a DataFrame with results\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fd9943d-8380-4deb-acc0-f25d655ae944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.586331</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.595477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.992462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.994975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.994975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.894472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.994975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy  Testing Accuracy  Overall Accuracy\n",
       "0  Logistic Regression           0.586331          0.616667          0.595477\n",
       "1        Decision Tree           1.000000          0.975000          0.992462\n",
       "2        Random Forest           1.000000          0.983333          0.994975\n",
       "3             AdaBoost           1.000000          0.983333          0.994975\n",
       "4          Naive Bayes           0.899281          0.883333          0.894472\n",
       "5              XGBoost           1.000000          0.983333          0.994975"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174c7eb-e179-4a3a-a322-2d57e5e4be01",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cab11e8-2d02-4460-8561-e612e21a5dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\safebite\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'model__bootstrap': True, 'model__max_depth': None, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 50}\n",
      "Best Cross-validation Accuracy for Random Forest: 0.9675324675324676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define hyperparameters to tune for Random Forest\n",
    "rf_param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'model__max_depth': [None, 10, 20, 30],  # Maximum depth of trees\n",
    "    'model__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "    'model__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at each leaf node\n",
    "    'model__bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model inside the pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Initialize GridSearchCV for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=rf_pipeline, param_grid=rf_param_grid, \n",
    "                              scoring='accuracy', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV to training data\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score for Random Forest\n",
    "best_rf_params = rf_grid_search.best_params_\n",
    "best_rf_score = rf_grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters for Random Forest: {best_rf_params}\")\n",
    "print(f\"Best Cross-validation Accuracy for Random Forest: {best_rf_score}\\n\")\n",
    "\n",
    "# Use the best estimator to predict on the test set\n",
    "rf_model = rf_grid_search.best_estimator_\n",
    "rf_train_preds =rf_model.predict(X_train)\n",
    "rf_test_preds =rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf84e5d2-354f-4b24-bf79-3401b70a4c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy: 0.9964028776978417\n",
      "Random Forest Test Accuracy: 0.9916666666666667\n",
      "Random Forest Overall Accuracy: 0.9949748743718593\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        87\n",
      "           1       0.97      1.00      0.99        33\n",
      "\n",
      "    accuracy                           0.99       120\n",
      "   macro avg       0.99      0.99      0.99       120\n",
      "weighted avg       0.99      0.99      0.99       120\n",
      "\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      "[[86  1]\n",
      " [ 0 33]]\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracies for Random Forest\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_preds)\n",
    "rf_overall_accuracy = (rf_train_accuracy * len(y_train) + rf_test_accuracy * len(y_test)) / (len(y_train) + len(y_test))\n",
    "\n",
    "# Print accuracies for Random Forest\n",
    "print(f\"Random Forest Training Accuracy: {rf_train_accuracy}\")\n",
    "print(f\"Random Forest Test Accuracy: {rf_test_accuracy}\")\n",
    "print(f\"Random Forest Overall Accuracy: {rf_overall_accuracy}\")\n",
    "\n",
    "# Classification report and confusion matrix for Random Forest\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_test_preds))\n",
    "print(\"\\nRandom Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a426ec2-98bd-45a1-920f-dc4fe9d29a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder=r\"C:\\Users\\Admin\\Desktop\\food_allergen_detection\\model\"\n",
    "model_filename=\"rf_model.pkl\"\n",
    "model_path = os.path.join(model_folder,model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "836c35ea-082e-4525-8614-14f7c0ba3f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Admin\\\\Desktop\\\\food_allergen_detection\\\\model\\\\rf_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(rf_model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
